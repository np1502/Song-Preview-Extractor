{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"data_transform.ipynb","provenance":[],"authorship_tag":"ABX9TyOyurij1Gr2m1QDBj2SStJE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"3JdhFYAeZdYe"},"source":["import os\n","import numpy as np\n","from os.path import join\n","import librosa\n","import subprocess\n","import spleeter\n","import shutil\n","from python_speech_features import mfcc\n","import torch\n","import torchaudio\n","import torchaudio.functional as F\n","import torchaudio.transforms as T\n","import pickle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sWZtOrM6z7bG"},"source":["class Audio_Util:\n","  def __init__(self,rate,mono,max_dur):\n","    super(Audio_Util).__init__()\n","    self.rate = rate\n","    self.mono = mono\n","    self.max_dur = max_dur\n","    \n","  def split_aud(self,filename):\n","    !spleeter separate -p spleeter:2stems -o output/ {filename}\n","\n","  def load_aud(self,filename):\n","    sig,sr = librosa.load(filename,mono = self.mono,sr = self.rate)\n","    return ((sig,sr))\n","\n","  def wave2mfcc(self,path):\n","    aud = self.load_aud(path)\n","    sig,sr = aud\n","    mfcc_feat = mfcc(sig,sr)\n","    mfcc_data= np.swapaxes(mfcc_feat, 0 ,1)\n","    mfcc_data = torch.Tensor(mfcc_data)\n","    return (mfcc_data)\n","\n","  def spectro_gram(self,path,n_mels=64, n_fft=20480, hop_len=None):\n","    aud = self.load_aud(path)\n","    sig,sr = aud\n","    sig = torch.Tensor(sig)\n","    #top_db = 80\n","\n","    spec = T.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n","    spec = T.AmplitudeToDB(top_db=80)(spec)\n","    spec = torch.add(spec[0],spec[1])\n","    return spec\n","\n","  def wavenet_encode(self, file):\n","    ckpts = \"/content/gdrive/MyDrive/wavenet-ckpt/wavenet-ckpt/model.ckpt-200000\"\n","    sr = 22050\n","    audio = u.load_audio(file,sample_length=6615000,sr = sr)\n","    #audio = librosa.load(file, sr=sr, mono=True, duration=300)\n","    #audio = np.array(audio)\n","    encoding = fastgen.encode(audio, ckpts, len(audio))\n","    return encoding\n","\n","  def main(self,song):\n","    filename = '/content/gdrive/MyDrive/music_data_X/'+song\n","    try:\n","      output_dict = {}\n","      # raw = self.wavenet_encode(filename)\n","      # output_dict[\"original\"] = raw\n","      raw = self.spectro_gram(filename)\n","      output_dict[\"original\"] = raw\n","      self.split_aud(filename)\n","      song = song[:-4]\n","      output_file = \"/content/output/\"+song\n","      for file in os.listdir(output_file):\n","        name = file[:-4]\n","        if(name == \"vocals\"):\n","          path = os.path.join(output_file,file)\n","          output_dict[name] = self.wave2mfcc(path)\n","        else:\n","          path = os.path.join(output_file,file)\n","          output_dict[name] = self.wavenet_encode(path)\n","      shutil.rmtree(output_file)\n","      return output_dict\n","    except Exception as e:\n","      print(e)\n","\n","  def df_loader(self,df,column_name):\n","    file_list = df[column_name].tolist()\n","    for file in file_list:\n","      curr_dict = self.main(file)\n","      file = file[:-4]\n","      file += \".pickle\"\n","      filename = os.path.join(\"/content/gdrive/MyDrive/Dictionary_data\",file)\n","      with open(filename, 'wb') as handle:\n","        pickle.dump(curr_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oQCXaS2p1s-d"},"source":["Audio_dl = Audio_Util(22050,False,300)\n","Audio_dl.df_loader(data,\"URI_Path\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VGiNHZIk0q1Q"},"source":["def flat(file):\n","  filepath = '/content/gdrive/MyDrive/Dict_y_data/'+file\n","  filepath2 = '/content/gdrive/MyDrive/Original_y_dict/'+file\n","  output_dict = pd.read_pickle(filepath)\n","  output_dict2 = pd.read_pickle(filepath2)\n","  output_dict['vocals'] = output_dict['vocals'].numpy()\n","  output_dict2['original'] = output_dict2['original'].numpy()\n","  output_dict['original'] = output_dict2['original']\n","  for vector in output_dict:\n","    #output_dict[vector] = output_dict[vector].numpy()\n","    min_v = np.min(output_dict[vector])\n","    range_v = np.max(output_dict[vector]) - min_v\n","    output_dict[vector] = (output_dict[vector] - min_v) / range_v\n","  output_dict['accompaniment']=output_dict['accompaniment'].reshape(1,-1)\n","  output_dict['vocals']=output_dict['vocals'].reshape(1,-1)\n","  output_dict['original']=output_dict['original'].reshape(1,-1)\n","  return output_dict\n","\n","def flat_loader(df,column_name):\n","    file_list = df[column_name].tolist()\n","    for file in file_list:\n","      print(file)\n","      file = file[:-4]\n","      file += \".pickle\"\n","      curr_dict = flat(file)\n","      filename = os.path.join(\"/content/gdrive/MyDrive/Vocals_Accompain\",file)\n","      with open(filename, 'wb') as handle:\n","        pickle.dump(curr_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DFSfFFPD1MIZ"},"source":["def reshape_stack(df, column_name):\n","  file_list = df[column_name].tolist()\n","  for file in file_list:\n","    print(file)\n","    file = file[:-4]\n","    file += \".pickle\"\n","    filename = os.path.join(\"/content/gdrive/MyDrive/Dict_y_data\",file)\n","    output_dict = pd.read_pickle(filename)\n","    curr_dict={}\n","    for key in output_dict:\n","      key_s = output_dict[key].shape[1]\n","      if key_s>16384:\n","        curr_dict[key] = output_dict[key][0][:16384].reshape(128,128)\n","      else :\n","        pad = 16384 - key_s\n","        curr_dict[key] = np.pad(output_dict[key][0], (0,pad), 'constant', constant_values=0).reshape(128,128)\n","    final = np.stack((curr_dict['accompaniment'], curr_dict['original'],curr_dict['vocals']))\n","    with open(filename, 'wb') as handle:\n","        pickle.dump(final, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"execution_count":null,"outputs":[]}]}